{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 batches of 32 records each, total records processed: 20.\n",
      "Train full vectors shape: (20, 1024)\n",
      "Train vectors shape: (16, 1024)\n",
      "Validation vectors shape: (4, 1024)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def read_and_prepare_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    columns_to_combine = ['title', 'make', 'model', 'features', 'accessories']\n",
    "    existing_columns = [col for col in columns_to_combine if col in data.columns]\n",
    "    if not existing_columns:\n",
    "        raise ValueError(\"None of the specified columns exist in the CSV file.\")\n",
    "    data['combined'] = data[existing_columns].apply(\n",
    "        lambda x: ' '.join(f\"{col}: {str(x[col]) if pd.notna(x[col]) else ''}\" for col in existing_columns), axis=1)\n",
    "    return data\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "model = BertModel.from_pretrained('bert-large-cased')\n",
    "model.eval()  # Set the model to inference mode\n",
    "\n",
    "def generate_bert_vectors(data, column_name, batch_size=10):\n",
    "    vectors = []\n",
    "    total_batches = (len(data) + batch_size - 1) // batch_size\n",
    "    records_processed = 0\n",
    "    for batch_index in range(total_batches):\n",
    "        batch = data[batch_index * batch_size:(batch_index + 1) * batch_size]\n",
    "        encoded_input = tokenizer(list(batch[column_name]), padding=True, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_input)\n",
    "        batch_vectors = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        vectors.append(batch_vectors)\n",
    "        records_processed += len(batch)\n",
    "        if (batch_index + 1) % (1000 // batch_size) == 0 or batch_index == total_batches - 1:\n",
    "            print(f\"Processed {batch_index + 1} batches of {batch_size} records each, total records processed: {records_processed}.\")\n",
    "    return np.vstack(vectors)\n",
    "\n",
    "# Read and process the data\n",
    "data = read_and_prepare_data('data/train.csv')\n",
    "# data = data.head(20)  # Limit the data for debugging purposes\n",
    "\n",
    "# Generate BERT vectors and save to a .npy file\n",
    "bert_vectors = generate_bert_vectors(data, 'combined', batch_size=32)\n",
    "np.save('data/processed/train_full_vectors.npy', bert_vectors)\n",
    "\n",
    "# Split data into train and validation sets after processing\n",
    "train_indices, valid_indices = train_test_split(np.arange(len(data)), test_size=0.2, random_state=42)\n",
    "train_vectors = bert_vectors[train_indices]\n",
    "valid_vectors = bert_vectors[valid_indices]\n",
    "\n",
    "# Save train and validation vectors\n",
    "np.save('data/processed/train_vectors.npy', train_vectors)\n",
    "np.save('data/processed/valid_vectors.npy', valid_vectors)\n",
    "\n",
    "# Print to confirm\n",
    "print(\"Train full vectors shape:\", bert_vectors.shape)\n",
    "print(\"Train vectors shape:\", train_vectors.shape)\n",
    "print(\"Validation vectors shape:\", valid_vectors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 batches of 32 records each, total records processed: 20.\n",
      "Validation vectors shape: (20, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Read and process the data\n",
    "data = read_and_prepare_data('data/test.csv')\n",
    "# data = data.head(20)  # Limit the data for debugging purposes\n",
    "test_vectors = generate_bert_vectors(data, 'combined', batch_size=32)\n",
    "\n",
    "# Save the vectors to a .npy file\n",
    "np.save('data/processed/test_vectors.npy', test_vectors)\n",
    "\n",
    "print(\"Validation vectors shape:\", test_vectors.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
