{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集读取完成\n",
      "训练集大小: (20000, 74)\n",
      "验证集大小: (5000, 74)\n",
      "全量训练集大小: (25000, 74)\n",
      "测试集大小: (10000, 74)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import json\n",
    "import math\n",
    "\n",
    "# 读取处理后的数据集\n",
    "X_train = pd.read_csv('data/processed/X_train.csv')\n",
    "y_train = pd.read_csv('data/processed/y_train.csv')\n",
    "X_valid = pd.read_csv('data/processed/X_valid.csv')\n",
    "y_valid = pd.read_csv('data/processed/y_valid.csv') \n",
    "X_train_full = pd.read_csv('data/processed/X_train_full.csv') \n",
    "y_train_full = pd.read_csv('data/processed/y_train_full.csv') \n",
    "X_test = pd.read_csv('data/processed/X_test.csv')\n",
    "\n",
    "print('数据集读取完成')\n",
    "print(f'训练集大小: {X_train.shape}')\n",
    "print(f'验证集大小: {X_valid.shape}')\n",
    "print(f'全量训练集大小: {X_train_full.shape}')\n",
    "print(f'测试集大小: {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA Version: 12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: (20000, 55)\n",
      "全量集: (25000, 55)\n",
      "测试集: (10000, 55)\n"
     ]
    }
   ],
   "source": [
    "# 直接定义列名配置\n",
    "del_cols = ['listing_id', 'original_reg_date', 'opc_scheme', 'lifespan', 'eco_category', 'indicative_price']\n",
    "text_cols = ['title', 'description', 'features', 'accessories']\n",
    "date_cols = ['reg_date']\n",
    "numeric_cols = ['manufactured', 'curb_weight', 'power', 'engine_cap', 'depreciation', 'coe', 'road_tax', \n",
    "                'dereg_value', 'mileage', 'omv', 'arf', 'year', 'month',\n",
    "                'text_brand_popularity_score', 'text_model_value_score', 'text_condition_score',\n",
    "                'text_feature_rarity_score', 'text_performance_score', 'text_sentiment_score']\n",
    "log_cols = ['manufactured', 'curb_weight', 'power_log', 'engine_cap_log', 'depreciation_log', 'coe', \n",
    "            'road_tax_log', 'dereg_value_log', 'mileage_log', 'omv_log', 'arf_log', 'year', 'month']\n",
    "root_cols = ['manufactured', 'curb_weight', 'power_root', 'engine_cap_root', 'depreciation_root', 'coe', \n",
    "             'road_tax_root', 'dereg_value_root', 'mileage_root', 'omv_root', 'arf_root', 'year', 'month']\n",
    "categorical_cols = ['make', 'model', 'type_of_vehicle', 'category', 'transmission', 'fuel_type', 'no_of_owners']\n",
    "\n",
    "# 更新变换列，添加GPT特征\n",
    "cat_nu_cols = [\n",
    "    \"manufactured\", \"curb_weight\", \"power\", \"engine_cap\", \"no_of_owners\", \"depreciation\", \n",
    "    \"coe\", \"road_tax\", \"dereg_value\", \"mileage\", \"omv\", \"arf\", \"make_target_encoded\",\n",
    "    \"text_brand_popularity_score\", \"text_model_value_score\", \"text_condition_score\",\n",
    "    \"text_feature_rarity_score\", \"text_performance_score\", \"text_sentiment_score\",\n",
    "    \"-\", \"almost new car\", \"coe car\", \"consignment car\", \"direct owner sale\", \n",
    "    \"electric cars\", \"hybrid cars\", \"imported used vehicle\", \"low mileage car\", \n",
    "    \"opc car\", \"parf car\", \"premium ad car\", \"rare & exotic\", \"sgcarmart warranty cars\", \n",
    "    \"sta evaluated car\", \"vintage cars\", \"type_of_vehicle_bus/mini bus\", \n",
    "    \"type_of_vehicle_hatchback\", \"type_of_vehicle_luxury sedan\", \n",
    "    \"type_of_vehicle_mid-sized sedan\", \"type_of_vehicle_mpv\", \"type_of_vehicle_others\", \n",
    "    \"type_of_vehicle_sports car\", \"type_of_vehicle_stationwagon\", \"type_of_vehicle_suv\", \n",
    "    \"type_of_vehicle_truck\", \"type_of_vehicle_van\", \"fuel_type_diesel\", \n",
    "    \"fuel_type_diesel-electric\", \"fuel_type_electric\", \"fuel_type_petrol\", \n",
    "    \"fuel_type_petrol-electric\", \"fuel_type_nan\", \"transmission_manual\", \"year\", \"month\"\n",
    "]\n",
    "\n",
    "cat_log_cols = [\n",
    "    \"manufactured\", \"curb_weight\", \"power_log\", \"engine_cap_log\", \"depreciation_log\", \n",
    "    \"coe\", \"road_tax_log\", \"dereg_value_log\", \"mileage_log\", \"omv_log\", \"arf_log\", \n",
    "    \"make_target_encoded\", \"text_brand_popularity_score\", \"text_model_value_score\", \n",
    "    \"text_condition_score\", \"text_feature_rarity_score\", \"text_performance_score\", \n",
    "    \"text_sentiment_score\", \"-\", \"almost new car\", \"coe car\", \"consignment car\", \n",
    "    \"direct owner sale\", \"electric cars\", \"hybrid cars\", \"imported used vehicle\", \n",
    "    \"low mileage car\", \"opc car\", \"parf car\", \"premium ad car\", \"rare & exotic\", \n",
    "    \"sgcarmart warranty cars\", \"sta evaluated car\", \"vintage cars\", \n",
    "    \"type_of_vehicle_bus/mini bus\", \"type_of_vehicle_hatchback\", \n",
    "    \"type_of_vehicle_luxury sedan\", \"type_of_vehicle_mid-sized sedan\", \n",
    "    \"type_of_vehicle_mpv\", \"type_of_vehicle_others\", \"type_of_vehicle_sports car\", \n",
    "    \"type_of_vehicle_stationwagon\", \"type_of_vehicle_suv\", \"type_of_vehicle_truck\", \n",
    "    \"type_of_vehicle_van\", \"fuel_type_diesel\", \"fuel_type_diesel-electric\", \n",
    "    \"fuel_type_electric\", \"fuel_type_petrol\", \"fuel_type_petrol-electric\", \n",
    "    \"fuel_type_nan\", \"transmission_manual\", \"year\", \"month\"\n",
    "]\n",
    "\n",
    "cat_root_cols = [\n",
    "    \"manufactured\", \"curb_weight\", \"power_root\", \"engine_cap_root\", \"depreciation_root\", \n",
    "    \"coe\", \"road_tax_root\", \"dereg_value_root\", \"mileage_root\", \"omv_root\", \"arf_root\", \n",
    "    \"make_target_encoded\", \"text_brand_popularity_score\", \"text_model_value_score\", \n",
    "    \"text_condition_score\", \"text_feature_rarity_score\", \"text_performance_score\", \n",
    "    \"text_sentiment_score\", \"-\", \"almost new car\", \"coe car\", \"consignment car\", \n",
    "    \"direct owner sale\", \"electric cars\", \"hybrid cars\", \"imported used vehicle\", \n",
    "    \"low mileage car\", \"opc car\", \"parf car\", \"premium ad car\", \"rare & exotic\", \n",
    "    \"sgcarmart warranty cars\", \"sta evaluated car\", \"vintage cars\", \n",
    "    \"type_of_vehicle_bus/mini bus\", \"type_of_vehicle_hatchback\", \n",
    "    \"type_of_vehicle_luxury sedan\", \"type_of_vehicle_mid-sized sedan\", \n",
    "    \"type_of_vehicle_mpv\", \"type_of_vehicle_others\", \"type_of_vehicle_sports car\", \n",
    "    \"type_of_vehicle_stationwagon\", \"type_of_vehicle_suv\", \"type_of_vehicle_truck\", \n",
    "    \"type_of_vehicle_van\", \"fuel_type_diesel\", \"fuel_type_diesel-electric\", \n",
    "    \"fuel_type_electric\", \"fuel_type_petrol\", \"fuel_type_petrol-electric\", \n",
    "    \"fuel_type_nan\", \"transmission_manual\", \"year\", \"month\"\n",
    "]\n",
    "\n",
    "# 丢弃log和root变换的结果\n",
    "X_train = X_train[cat_nu_cols]\n",
    "X_valid = X_valid[cat_nu_cols]\n",
    "X_test = X_test[cat_nu_cols]\n",
    "X_train_full = X_train_full[cat_nu_cols]\n",
    "\n",
    "print(f'训练集: {X_train.shape}')\n",
    "print(f'全量集: {X_train_full.shape}')\n",
    "print(f'测试集: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\10021\\anaconda3\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征维度:\n",
      "原始特征: 55\n",
      "UMAP特征: 8\n",
      "组合特征: 63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap.umap_ import UMAP  # 正确的导入方式\n",
    "\n",
    "# 加载BERT向量\n",
    "bert_train_vectors = np.load('data/processed/train_vectors.npy')\n",
    "bert_valid_vectors = np.load('data/processed/valid_vectors.npy')\n",
    "bert_train_full_vectors = np.load('data/processed/train_full_vectors.npy')\n",
    "bert_test_vectors = np.load('data/processed/test_vectors.npy')\n",
    "\n",
    "# BERT降维\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# UMAP参数设置\n",
    "umap = UMAP(\n",
    "    n_components=8,\n",
    "    n_neighbors=20,\n",
    "    min_dist=0.1,\n",
    "    metric='cosine',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# umap = UMAP(\n",
    "#     n_components=16,\n",
    "#     n_neighbors=30,\n",
    "#     min_dist=0.3,\n",
    "#     metric='cosine',\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# umap = UMAP(\n",
    "#     n_components=24,\n",
    "#     n_neighbors=50,\n",
    "#     min_dist=0.5,\n",
    "#     metric='cosine',\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# 对BERT向量进行UMAP降维\n",
    "bert_train_scaled = scaler.fit_transform(bert_train_vectors)\n",
    "bert_train_umap = umap.fit_transform(bert_train_scaled)\n",
    "\n",
    "# 对验证集和测试集应用相同的转换\n",
    "bert_valid_scaled = scaler.transform(bert_valid_vectors)\n",
    "bert_valid_umap = umap.transform(bert_valid_scaled)\n",
    "\n",
    "bert_test_scaled = scaler.transform(bert_test_vectors)\n",
    "bert_test_umap = umap.transform(bert_test_scaled)\n",
    "\n",
    "# 对完整训练集进行转换\n",
    "bert_train_full_scaled = scaler.transform(bert_train_full_vectors)\n",
    "bert_train_full_umap = umap.transform(bert_train_full_scaled)\n",
    "\n",
    "# 拼接特征\n",
    "X_train_combined = np.hstack((X_train[cat_nu_cols].values, bert_train_umap))\n",
    "X_valid_combined = np.hstack((X_valid[cat_nu_cols].values, bert_valid_umap))\n",
    "X_test_combined = np.hstack((X_test[cat_nu_cols].values, bert_test_umap))\n",
    "X_train_full_combined = np.hstack((X_train_full[cat_nu_cols].values, bert_train_full_umap))\n",
    "\n",
    "\n",
    "# 打印维度信息\n",
    "print(\"特征维度:\")\n",
    "print(f\"原始特征: {X_train[cat_nu_cols].shape[1]}\")\n",
    "print(f\"UMAP特征: {bert_train_umap.shape[1]}\")\n",
    "print(f\"组合特征: {X_train_combined.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 63)\n",
      "(10000, 63)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full_combined.shape)\n",
    "print(X_test_combined.shape)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\n",
    "X_valid = torch.tensor(X_valid_combined, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\n",
    "X_train_full = torch.tensor(X_train_full_combined, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "y_valid = torch.tensor(y_valid.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "y_train_full = torch.tensor(y_train_full.values, dtype=torch.float32).view(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Initializing weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def train_network(model_class, input_dim, X_train_tensor, y_train_tensor, X_valid_tensor, y_valid_tensor, lr=0.001, wd=0, seed=42):\n",
    "    set_seed(seed)  # Set the random seed for reproducibility\n",
    "    \n",
    "    # Initialize the model with the provided model class and input dimension\n",
    "    model = model_class(input_dim)\n",
    "    model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    # Convert data to tensors and create data loaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "    y_valid_n = y_valid_tensor.cpu().numpy()\n",
    "\n",
    "    epochs = 100\n",
    "    best_rmse = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_valid_pred = model(X_valid_tensor).cpu().numpy().flatten()\n",
    "            mse_valid = mean_squared_error(y_valid_n, y_valid_pred)\n",
    "            rmse_valid = np.sqrt(mse_valid)\n",
    "        if rmse_valid < best_rmse:\n",
    "            best_rmse = rmse_valid\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    print(f'Best Valid RMSE: {best_rmse:.4f}')\n",
    "    return best_rmse\n",
    "\n",
    "input_dim = X_train_combined.shape[1]\n",
    "print(input_dim)\n",
    "        \n",
    "# input_dim = len(cat_nu_cols)\n",
    "# print(input_dim)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_multiple_seeds_and_average(model_class, input_dim, X_train, y_train, X_valid, y_valid, lr, wd):\n",
    "    total_rmse = 0\n",
    "    num_seeds = 10  # 种子数量从 40 到 49，共 10 个\n",
    "    for seed in range(40, 50):  # 从 40 到 49\n",
    "        rmse = train_network(model_class, input_dim, X_train, y_train, X_valid, y_valid, lr, wd, seed)\n",
    "        total_rmse += rmse\n",
    "    average_rmse = total_rmse / num_seeds  # 计算平均 RMSE\n",
    "    print(f\"Average RMSE for seeds 40 to 49: {average_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29282.6602\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29965.7734\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 28235.6035\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29435.5547\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29096.4844\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 28660.7207\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 28739.4512\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29053.4004\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 30842.9785\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29083.4219\n",
      "Average RMSE for seeds 40 to 49: 29239.6049\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24435.5801\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25168.1211\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24917.9355\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26982.2344\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24666.9141\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24109.6855\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23795.8066\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25188.3867\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25727.8828\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26188.6777\n",
      "Average RMSE for seeds 40 to 49: 25118.1225\n",
      "Best Valid RMSE: 27894.9590\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 28147.3926\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27671.0039\n",
      "Best Valid RMSE: 28570.7051\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29701.9883\n",
      "Best Valid RMSE: 27981.3281\n",
      "Best Valid RMSE: 27493.9473\n",
      "Best Valid RMSE: 28103.6934\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27952.6367\n",
      "Best Valid RMSE: 29086.7539\n",
      "Average RMSE for seeds 40 to 49: 28260.4408\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(MLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-2, 0)\n",
    "run_with_multiple_seeds_and_average(MLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)\n",
    "run_with_multiple_seeds_and_average(MLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26457.8633\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26193.6738\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26207.1133\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26997.6719\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24965.5000\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25879.0449\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26302.8281\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26020.3203\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27951.2715\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25890.0137\n",
      "Average RMSE for seeds 40 to 49: 26286.5301\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24933.8926\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26187.6973\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25018.0215\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24824.9004\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24928.3555\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26618.4590\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26352.5039\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25565.9844\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27351.2148\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24436.0293\n",
      "Average RMSE for seeds 40 to 49: 25621.7059\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25585.4824\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25445.9141\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25794.1543\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24093.2559\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24660.2285\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25787.7910\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26636.5527\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25859.9297\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27472.9277\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24264.6797\n",
      "Average RMSE for seeds 40 to 49: 25560.0916\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24435.5801\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25168.1211\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24917.9355\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26982.2344\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24666.9141\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24109.6855\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23795.8066\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25188.3867\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25727.8828\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26188.6777\n",
      "Average RMSE for seeds 40 to 49: 25118.1225\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(MLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 1e-1)\n",
    "run_with_multiple_seeds_and_average(MLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 1e-2)\n",
    "run_with_multiple_seeds_and_average(MLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 1e-3)\n",
    "run_with_multiple_seeds_and_average(MLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26125.9062\n",
      "Best Valid RMSE: 24921.6641\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26581.1191\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27020.0059\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24582.0215\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24528.7734\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26733.9551\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25791.9004\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27375.8320\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26803.4141\n",
      "Average RMSE for seeds 40 to 49: 26046.4592\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25483.8105\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26133.1992\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24843.3105\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25046.2070\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25085.9023\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24571.6328\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24858.9414\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25072.3008\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27766.2676\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23801.8574\n",
      "Average RMSE for seeds 40 to 49: 25266.3430\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25352.3535\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27246.8574\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26194.7656\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26849.0566\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25158.9766\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24707.2363\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24366.7676\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26663.3145\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27573.2051\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25714.6504\n",
      "Average RMSE for seeds 40 to 49: 25982.7184\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(MLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 1e-4)\n",
    "run_with_multiple_seeds_and_average(MLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 1e-5)\n",
    "run_with_multiple_seeds_and_average(MLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other NN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWithBertModel(nn.Module):\n",
    "    def __init__(self, input_dim, bert_dim=8, reduced_dim=16):\n",
    "        super(MLPWithBertModel, self).__init__()\n",
    "        # Assuming the BERT output is at the last part of the input\n",
    "        self.bert_processor = nn.Sequential(\n",
    "            nn.Linear(bert_dim, reduced_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # New input dimension after concatenating reduced BERT output\n",
    "        new_input_dim = input_dim - bert_dim + reduced_dim\n",
    "        \n",
    "        self.layer1 = nn.Linear(new_input_dim, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Initializing weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Assuming x is the input where the last 8 elements are the BERT vector\n",
    "        bert_vector = x[:, -8:]  # Extract the last 8 dimensions\n",
    "        other_features = x[:, :-8]  # Extract all other features\n",
    "        \n",
    "        # Process the BERT vector\n",
    "        processed_bert = self.bert_processor(bert_vector)\n",
    "        \n",
    "        # Concatenate the processed BERT output with other features\n",
    "        x = torch.cat((other_features, processed_bert), dim=1)\n",
    "        \n",
    "        # Feed through the subsequent layers\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26703.6641\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24819.3340\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27647.3672\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 28471.7637\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25371.4707\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24761.3027\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27227.7070\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26635.1699\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23765.0293\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27358.3848\n",
      "Average RMSE for seeds 40 to 49: 26276.1193\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(MLPWithBertModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDropoutModel(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0.5):\n",
    "        super(MLPDropoutModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 39446.8633\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 39724.5430\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 38784.5352\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 38807.5625\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 41661.5234\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 39772.0430\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 40497.1992\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 44484.5977\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 42918.1680\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 38590.3125\n",
      "Average RMSE for seeds 40 to 49: 40468.7348\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(MLPDropoutModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDropoutModel(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0.1):\n",
    "        super(MLPDropoutModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 30420.2422\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29679.4355\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 31220.8086\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29977.5039\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29877.0801\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 31880.7109\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 30816.5488\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29205.3633\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 31278.4980\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 31060.9258\n",
      "Average RMSE for seeds 40 to 49: 30541.7117\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(MLPDropoutModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBNModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPBNModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)  # Batch normalization layer for the first layer output\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)   # Batch normalization layer for the second layer output\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)   # Batch normalization layer for the third layer output\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Initializing weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.layer1(x)))  # Apply BatchNorm after linear transformation, before ReLU\n",
    "        x = self.relu(self.bn2(self.layer2(x)))\n",
    "        x = self.relu(self.bn3(self.layer3(x)))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.01)  # Initialize biases to a small constant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Valid RMSE: 142330.3281\n",
      "Best Valid RMSE: 138713.0625\n",
      "Best Valid RMSE: 142498.4688\n",
      "Best Valid RMSE: 140954.1875\n",
      "Best Valid RMSE: 143754.3125\n",
      "Best Valid RMSE: 147133.5312\n",
      "Best Valid RMSE: 141508.2031\n",
      "Best Valid RMSE: 146971.8594\n",
      "Best Valid RMSE: 139035.9375\n",
      "Best Valid RMSE: 142847.6562\n",
      "Average RMSE for seeds 40 to 49: 142574.7547\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(MLPBNModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeeperMLPModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeeperMLPModel, self).__init__()\n",
    "        # Increasing the depth with more layers\n",
    "        self.layer1 = nn.Linear(input_dim, 256)\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.layer3 = nn.Linear(128, 128)\n",
    "        self.layer4 = nn.Linear(128, 64)\n",
    "        self.layer5 = nn.Linear(64, 64)\n",
    "        self.layer6 = nn.Linear(64, 32)\n",
    "        self.layer7 = nn.Linear(32, 16)\n",
    "        self.output_layer = nn.Linear(16, 1)\n",
    "        \n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Initializing weights with Kaiming initialization suitable for ReLU\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.relu(self.layer4(x))\n",
    "        x = self.relu(self.layer5(x))\n",
    "        x = self.relu(self.layer6(x))\n",
    "        x = self.relu(self.layer7(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        # Apply Kaiming He initialization to all linear layers in the model\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27056.4609\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24468.6035\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23973.1699\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27135.1504\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23657.3457\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23696.1895\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26114.7480\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25216.7930\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24818.8945\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25326.0664\n",
      "Average RMSE for seeds 40 to 49: 25146.3422\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(DeeperMLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeeperMLPWithBertModel(nn.Module):\n",
    "    def __init__(self, input_dim, bert_dim=8, reduced_bert_dim=128):\n",
    "        super(DeeperMLPWithBertModel, self).__init__()\n",
    "        \n",
    "        # Processing the BERT vector\n",
    "        self.bert_processor = nn.Sequential(\n",
    "            nn.Linear(bert_dim, reduced_bert_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # New input dimension after reducing the BERT vector and concatenating it back\n",
    "        new_input_dim = input_dim - bert_dim + reduced_bert_dim\n",
    "\n",
    "        # Increasing the depth with more layers\n",
    "        self.layer1 = nn.Linear(new_input_dim, 256)\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.layer3 = nn.Linear(128, 128)\n",
    "        self.layer4 = nn.Linear(128, 64)\n",
    "        self.layer5 = nn.Linear(64, 64)\n",
    "        self.layer6 = nn.Linear(64, 32)\n",
    "        self.layer7 = nn.Linear(32, 16)\n",
    "        self.output_layer = nn.Linear(16, 1)\n",
    "        \n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Initializing weights with Kaiming initialization suitable for ReLU\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split the input into BERT vector and other features\n",
    "        bert_vector = x[:, -8:]  # Assuming BERT vector is the last 8 elements\n",
    "        other_features = x[:, :-8]  # The rest of the features\n",
    "\n",
    "        # Process the BERT vector\n",
    "        processed_bert = self.bert_processor(bert_vector)\n",
    "\n",
    "        # Concatenate the processed BERT vector with other features\n",
    "        x = torch.cat((other_features, processed_bert), dim=1)\n",
    "\n",
    "        # Sequentially process through all layers\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.relu(self.layer4(x))\n",
    "        x = self.relu(self.layer5(x))\n",
    "        x = self.relu(self.layer6(x))\n",
    "        x = self.relu(self.layer7(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26850.2734\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 28228.9844\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26440.4453\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23957.5000\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25107.8770\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23834.5000\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24558.5254\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29403.0195\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23973.0527\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24926.8789\n",
      "Average RMSE for seeds 40 to 49: 25728.1057\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(DeeperMLPWithBertModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepResidualMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeepResidualMLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 256)\n",
    "        self.layer2 = nn.Linear(256, 256)\n",
    "        self.layer3 = nn.Linear(256, 256)\n",
    "        self.layer4 = nn.Linear(256, 256)\n",
    "        self.layer5 = nn.Linear(256, 256)\n",
    "        self.output_layer = nn.Linear(256, 1)\n",
    "        \n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Initializing weights with He initialization suitable for ReLU\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.relu(self.layer1(x))\n",
    "        \n",
    "        # Residual block 1\n",
    "        out = self.relu(self.layer2(identity))\n",
    "        x = out + identity  # Ensure no inplace operation\n",
    "        \n",
    "        # Residual block 2\n",
    "        identity = x  # Update identity to current x before the next block\n",
    "        out = self.relu(self.layer3(x))\n",
    "        x = out + identity\n",
    "        \n",
    "        # Residual block 3\n",
    "        identity = x\n",
    "        out = self.relu(self.layer4(x))\n",
    "        x = out + identity\n",
    "        \n",
    "        # Residual block 4\n",
    "        identity = x\n",
    "        out = self.relu(self.layer5(x))\n",
    "        x = out + identity\n",
    "        \n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24050.7891\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27886.6406\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24212.5938\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24250.9727\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24007.9141\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23162.4062\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24812.3711\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24609.7969\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23728.8730\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23343.9824\n",
      "Average RMSE for seeds 40 to 49: 24406.6340\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(DeepResidualMLP, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeeperResidualMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeeperResidualMLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 256)\n",
    "        self.layer2 = nn.Linear(256, 256)\n",
    "        self.layer3 = nn.Linear(256, 256)\n",
    "        self.layer4 = nn.Linear(256, 256)\n",
    "        self.layer5 = nn.Linear(256, 256)\n",
    "        # Adding intermediate layers\n",
    "        self.layer6 = nn.Linear(256, 128)\n",
    "        self.layer7 = nn.Linear(128, 64)\n",
    "        self.layer8 = nn.Linear(64, 32)\n",
    "        self.layer9 = nn.Linear(32, 16)\n",
    "        self.output_layer = nn.Linear(16, 1)\n",
    "        \n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Initializing weights with He initialization suitable for ReLU\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input pass\n",
    "        identity = x\n",
    "        x = self.relu(self.layer1(x))\n",
    "        \n",
    "        # Residual block 1\n",
    "        out = self.relu(self.layer2(x))\n",
    "        out = out + x  # Replacing inplace operation with out-of-place operation\n",
    "        \n",
    "        # Residual block 2\n",
    "        x = self.relu(self.layer3(out))\n",
    "        x = x + out  # Replacing inplace operation with out-of-place operation\n",
    "        \n",
    "        # Residual block 3\n",
    "        out = self.relu(self.layer4(x))\n",
    "        out = out + x  # Replacing inplace operation with out-of-place operation\n",
    "        \n",
    "        # Residual block 4\n",
    "        x = self.relu(self.layer5(out))\n",
    "        x = x + out  # Replacing inplace operation with out-of-place operation\n",
    "    \n",
    "        # Gradual reduction layers\n",
    "        x = self.relu(self.layer6(x))\n",
    "        x = self.relu(self.layer7(x))\n",
    "        x = self.relu(self.layer8(x))\n",
    "        x = self.relu(self.layer9(x))\n",
    "    \n",
    "        # Output pass\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23998.5527\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23995.7695\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24411.0527\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 29195.5312\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24530.7578\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26299.5176\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24565.1309\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23506.8828\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25207.9688\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26825.5410\n",
      "Average RMSE for seeds 40 to 49: 25253.6705\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(DeeperResidualMLP, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.key_layer = nn.Linear(feature_dim, feature_dim, bias=False)\n",
    "        self.query_layer = nn.Linear(feature_dim, feature_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        query = self.query_layer(x).unsqueeze(1)  # Adding batch dimension\n",
    "        key = self.key_layer(x).unsqueeze(-1)  # Adding an extra dimension for bmm\n",
    "        \n",
    "        # Compute attention scores and apply softmax\n",
    "        scores = torch.bmm(query, key)  # Should work as both are 3D now\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # Apply weights to the original input features, using batch matrix multiplication\n",
    "        attended = torch.bmm(weights, x.unsqueeze(1))  # x also needs to be 3D\n",
    "        return attended.squeeze(1)  # Remove the extra dimension to match expected output shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DeepResidualMLPWithAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeepResidualMLPWithAttention, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 256)\n",
    "        self.layer2 = nn.Linear(256, 256)\n",
    "        self.layer3 = nn.Linear(256, 256)\n",
    "        self.layer4 = nn.Linear(256, 256)\n",
    "        self.layer5 = nn.Linear(256, 256)\n",
    "        self.attention = Attention(256)  # Attention layer after layer5\n",
    "        self.output_layer = nn.Linear(256, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Initializing weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.relu(self.layer1(x))\n",
    "        \n",
    "        out = self.relu(self.layer2(x))\n",
    "        out = out + x  # Use out-of-place operation\n",
    "\n",
    "        x = self.relu(self.layer3(out))\n",
    "        x = x + out  # Use out-of-place operation\n",
    "\n",
    "        out = self.relu(self.layer4(x))\n",
    "        out = out + x  # Use out-of-place operation\n",
    "\n",
    "        x = self.relu(self.layer5(out))\n",
    "        x = x + out  # Use out-of-place operation\n",
    "\n",
    "        # Apply attention\n",
    "        x = self.attention(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23995.5645\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27950.9746\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26850.6328\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24806.5977\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24531.3066\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24396.6992\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23207.5859\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27993.7988\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24122.9551\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 28209.8926\n",
      "Average RMSE for seeds 40 to 49: 25606.6008\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(DeepResidualMLPWithAttention, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroaderMLPModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BroaderMLPModel, self).__init__()\n",
    "        # Adjusting the layer sizes to match the diagram\n",
    "        self.layer1 = nn.Linear(input_dim, 512)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.layer3 = nn.Linear(256, 128)\n",
    "        self.layer4 = nn.Linear(128, 64)\n",
    "        self.output_layer = nn.Linear(64, 1)\n",
    "        \n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Initializing weights with Kaiming initialization suitable for ReLU\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.relu(self.layer4(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        # Apply Kaiming He initialization to all linear layers in the model\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.fill_(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25440.8809\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23883.6855\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26357.7812\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 27368.0566\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 26315.0820\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24414.5234\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23893.6387\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 25038.7246\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 23528.3613\n",
      "Early stopping triggered.\n",
      "Best Valid RMSE: 24964.4375\n",
      "Average RMSE for seeds 40 to 49: 25120.5172\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_average(BroaderMLPModel, input_dim, X_train, y_train, X_valid, y_valid, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def train_network_and_get_result(pre_best_rmse, model_class, input_dim, X_train_tensor, y_train_tensor, X_valid_tensor, y_valid_tensor, X_test_tensor, lr=0.001, wd=0, seed=42):\n",
    "    set_seed(seed)  # Set the random seed for reproducibility\n",
    "    \n",
    "    # Initialize the model with the provided model class and input dimension\n",
    "    model = model_class(input_dim)\n",
    "    model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    # Convert data to tensors and create data loaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "    y_valid_n = y_valid_tensor.cpu().numpy()\n",
    "\n",
    "    epochs = 100\n",
    "    best_rmse = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_valid_pred = model(X_valid_tensor).cpu().numpy().flatten()\n",
    "            mse_valid = mean_squared_error(y_valid_n, y_valid_pred)\n",
    "            rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "        if rmse_valid < best_rmse:\n",
    "            best_rmse = rmse_valid\n",
    "            best_model = copy.deepcopy(model)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "            \n",
    "    if pre_best_rmse > best_rmse:\n",
    "        pre_best_rmse = best_rmse\n",
    "        torch.save(best_model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "        \n",
    "        best_model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_valid_pred = best_model(X_valid_tensor).cpu().numpy().flatten()\n",
    "            # mse_valid = mean_squared_error(y_valid_n, y_valid_pred)\n",
    "            # rmse_valid = np.sqrt(mse_valid)\n",
    "            # print(rmse_valid)\n",
    "        valid_predictions_df = pd.DataFrame({\n",
    "            'Id': range(len(y_valid_pred)),\n",
    "            'Predicted': y_valid_pred\n",
    "        })\n",
    "        valid_predictions_df.to_csv('data/nn_valid.csv', index=False)\n",
    "        print(\"Validation results saved to data/nn_valid.csv\")\n",
    "\n",
    "        \n",
    "        best_model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_test_pred = best_model(X_test_tensor).cpu().numpy().flatten()\n",
    "        test_predictions_df = pd.DataFrame({\n",
    "            'Id': range(len(y_test_pred)),\n",
    "            'Predicted': y_test_pred\n",
    "        })\n",
    "        test_predictions_df.to_csv('data/nn_test.csv', index=False)\n",
    "        print(\"Test results saved to data/nn_test.csv\")\n",
    "            \n",
    "    return pre_best_rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_multiple_seeds_and_get_best(model_class, input_dim, X_train, y_train, X_valid, y_valid, X_test, lr, wd):\n",
    "    pre_best_rmse = 1e6\n",
    "    for seed in range(100):\n",
    "        best_rmse = train_network_and_get_result(pre_best_rmse, model_class, input_dim, X_train, y_train, X_valid, y_valid, X_test, lr, wd, seed)\n",
    "        pre_best_rmse = best_rmse\n",
    "        print(f\"Best RMSE till round {seed+1} : {pre_best_rmse:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results saved to data/nn_valid.csv\n",
      "Test results saved to data/nn_test.csv\n",
      "Best RMSE till round 1 : 24816.1582\n",
      "Validation results saved to data/nn_valid.csv\n",
      "Test results saved to data/nn_test.csv\n",
      "Best RMSE till round 2 : 24116.5840\n",
      "Best RMSE till round 3 : 24116.5840\n",
      "Best RMSE till round 4 : 24116.5840\n",
      "Validation results saved to data/nn_valid.csv\n",
      "Test results saved to data/nn_test.csv\n",
      "Best RMSE till round 5 : 23776.6270\n",
      "Best RMSE till round 6 : 23776.6270\n",
      "Best RMSE till round 7 : 23776.6270\n",
      "Best RMSE till round 8 : 23776.6270\n",
      "Best RMSE till round 9 : 23776.6270\n",
      "Validation results saved to data/nn_valid.csv\n",
      "Test results saved to data/nn_test.csv\n",
      "Best RMSE till round 10 : 23739.2695\n",
      "Best RMSE till round 11 : 23739.2695\n",
      "Best RMSE till round 12 : 23739.2695\n",
      "Best RMSE till round 13 : 23739.2695\n",
      "Best RMSE till round 14 : 23739.2695\n",
      "Best RMSE till round 15 : 23739.2695\n",
      "Best RMSE till round 16 : 23739.2695\n",
      "Best RMSE till round 17 : 23739.2695\n",
      "Best RMSE till round 18 : 23739.2695\n",
      "Best RMSE till round 19 : 23739.2695\n",
      "Validation results saved to data/nn_valid.csv\n",
      "Test results saved to data/nn_test.csv\n",
      "Best RMSE till round 20 : 23284.8867\n",
      "Best RMSE till round 21 : 23284.8867\n",
      "Best RMSE till round 22 : 23284.8867\n",
      "Validation results saved to data/nn_valid.csv\n",
      "Test results saved to data/nn_test.csv\n",
      "Best RMSE till round 23 : 23167.5820\n",
      "Best RMSE till round 24 : 23167.5820\n",
      "Best RMSE till round 25 : 23167.5820\n",
      "Best RMSE till round 26 : 23167.5820\n",
      "Best RMSE till round 27 : 23167.5820\n",
      "Best RMSE till round 28 : 23167.5820\n",
      "Best RMSE till round 29 : 23167.5820\n",
      "Best RMSE till round 30 : 23167.5820\n",
      "Best RMSE till round 31 : 23167.5820\n",
      "Best RMSE till round 32 : 23167.5820\n",
      "Best RMSE till round 33 : 23167.5820\n",
      "Best RMSE till round 34 : 23167.5820\n",
      "Best RMSE till round 35 : 23167.5820\n",
      "Best RMSE till round 36 : 23167.5820\n",
      "Best RMSE till round 37 : 23167.5820\n",
      "Best RMSE till round 38 : 23167.5820\n",
      "Best RMSE till round 39 : 23167.5820\n",
      "Best RMSE till round 40 : 23167.5820\n",
      "Best RMSE till round 41 : 23167.5820\n",
      "Best RMSE till round 42 : 23167.5820\n",
      "Best RMSE till round 43 : 23167.5820\n",
      "Best RMSE till round 44 : 23167.5820\n",
      "Best RMSE till round 45 : 23167.5820\n",
      "Validation results saved to data/nn_valid.csv\n",
      "Test results saved to data/nn_test.csv\n",
      "Best RMSE till round 46 : 23162.4062\n",
      "Best RMSE till round 47 : 23162.4062\n",
      "Best RMSE till round 48 : 23162.4062\n",
      "Best RMSE till round 49 : 23162.4062\n",
      "Best RMSE till round 50 : 23162.4062\n",
      "Best RMSE till round 51 : 23162.4062\n",
      "Best RMSE till round 52 : 23162.4062\n",
      "Best RMSE till round 53 : 23162.4062\n",
      "Best RMSE till round 54 : 23162.4062\n",
      "Best RMSE till round 55 : 23162.4062\n",
      "Best RMSE till round 56 : 23162.4062\n",
      "Best RMSE till round 57 : 23162.4062\n",
      "Best RMSE till round 58 : 23162.4062\n",
      "Best RMSE till round 59 : 23162.4062\n",
      "Best RMSE till round 60 : 23162.4062\n",
      "Best RMSE till round 61 : 23162.4062\n",
      "Best RMSE till round 62 : 23162.4062\n",
      "Best RMSE till round 63 : 23162.4062\n",
      "Best RMSE till round 64 : 23162.4062\n",
      "Best RMSE till round 65 : 23162.4062\n",
      "Best RMSE till round 66 : 23162.4062\n",
      "Best RMSE till round 67 : 23162.4062\n",
      "Best RMSE till round 68 : 23162.4062\n",
      "Best RMSE till round 69 : 23162.4062\n",
      "Best RMSE till round 70 : 23162.4062\n",
      "Best RMSE till round 71 : 23162.4062\n",
      "Best RMSE till round 72 : 23162.4062\n",
      "Best RMSE till round 73 : 23162.4062\n",
      "Best RMSE till round 74 : 23162.4062\n",
      "Best RMSE till round 75 : 23162.4062\n",
      "Best RMSE till round 76 : 23162.4062\n",
      "Best RMSE till round 77 : 23162.4062\n",
      "Best RMSE till round 78 : 23162.4062\n",
      "Best RMSE till round 79 : 23162.4062\n",
      "Best RMSE till round 80 : 23162.4062\n",
      "Best RMSE till round 81 : 23162.4062\n",
      "Best RMSE till round 82 : 23162.4062\n",
      "Best RMSE till round 83 : 23162.4062\n",
      "Best RMSE till round 84 : 23162.4062\n",
      "Best RMSE till round 85 : 23162.4062\n",
      "Best RMSE till round 86 : 23162.4062\n",
      "Best RMSE till round 87 : 23162.4062\n",
      "Best RMSE till round 88 : 23162.4062\n",
      "Best RMSE till round 89 : 23162.4062\n",
      "Best RMSE till round 90 : 23162.4062\n",
      "Best RMSE till round 91 : 23162.4062\n",
      "Best RMSE till round 92 : 23162.4062\n",
      "Best RMSE till round 93 : 23162.4062\n",
      "Best RMSE till round 94 : 23162.4062\n",
      "Best RMSE till round 95 : 23162.4062\n",
      "Best RMSE till round 96 : 23162.4062\n",
      "Best RMSE till round 97 : 23162.4062\n",
      "Best RMSE till round 98 : 23162.4062\n",
      "Best RMSE till round 99 : 23162.4062\n",
      "Best RMSE till round 100 : 23162.4062\n"
     ]
    }
   ],
   "source": [
    "run_with_multiple_seeds_and_get_best(DeepResidualMLP, input_dim, X_train, y_train, X_valid, y_valid, X_test, 1e-3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def full_train_network_and_get_result(model, cat_nu_cols, X_train_full, y_train_full, X_test, lr=0.001, wd=0, seed=42):\n",
    "#     set_seed(seed)  # Set the random seed for reproducibility    \n",
    "#     train_indices, valid_indices = train_test_split(np.arange(len(X_train_full)), test_size=0.2, random_state=42)\n",
    "#     X_train = X_train_full[train_indices]\n",
    "#     y_train = y_train_full.iloc[train_indices]\n",
    "#     X_valid = X_train_full[valid_indices]\n",
    "#     y_valid = y_train_full.iloc[valid_indices]\n",
    "    \n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "#     X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "#     y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "#     train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "#     X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32)\n",
    "#     y_valid_tensor = torch.tensor(y_valid.values, dtype=torch.float32).view(-1, 1)\n",
    "#     X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "#     epochs = 100\n",
    "#     best_rmse = float('inf')\n",
    "#     best_model = None\n",
    "#     patience = 10\n",
    "#     patience_counter = 0\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         for inputs, targets in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             y_valid_pred = model(X_valid_tensor).numpy().flatten()\n",
    "#             mse_valid = mean_squared_error(y_valid_tensor.numpy(), y_valid_pred)\n",
    "#             rmse_valid = np.sqrt(mse_valid)\n",
    "\n",
    "#         if rmse_valid < best_rmse:\n",
    "#             best_rmse = rmse_valid\n",
    "#             best_model = model\n",
    "#             torch.save(best_model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "#             patience_counter = 0\n",
    "#         else:\n",
    "#             patience_counter += 1\n",
    "#             if patience_counter >= patience:\n",
    "#                 print(\"Early stopping triggered.\")\n",
    "#                 break\n",
    "\n",
    "#     print(f'Best Valid RMSE: {best_rmse:.4f}')\n",
    "\n",
    "#     # Saving validation predictions to a CSV file\n",
    "#     valid_predictions_df = pd.DataFrame({\n",
    "#         'Id': range(len(y_valid_pred)),\n",
    "#         'Predicted': y_valid_pred\n",
    "#     })\n",
    "#     valid_predictions_df.to_csv('data/full_nn_valid.csv', index=False)\n",
    "#     print(\"Validation results saved to data/full_nn_valid.csv\")\n",
    "\n",
    "#     # Saving test predictions to a CSV file if the best model was found\n",
    "#     if best_model:\n",
    "#         best_model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             y_test_pred = best_model(X_test_tensor).numpy().flatten()\n",
    "\n",
    "#         test_predictions_df = pd.DataFrame({\n",
    "#             'Id': range(len(y_test_pred)),\n",
    "#             'Predicted': y_test_pred\n",
    "#         })\n",
    "#         test_predictions_df.to_csv('data/full_nn_test.csv', index=False)\n",
    "#         print(\"Test results saved to data/full_nn_test.csv\")\n",
    "        \n",
    "# model = DeeperMLPModel(input_dim)\n",
    "# full_train_network_and_get_result(model, cat_nu_cols, X_train_full, y_train_full , X_test,0.001, 0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 选择表现最好的模型进行最终训练和预测\n",
    "# best_model = DeeperMLPModel(input_dim)\n",
    "\n",
    "# print(\"使用全量数据训练最终模型...\")\n",
    "# # 转换数据为tensor\n",
    "# X_train_full_tensor = torch.tensor(X_train_full[cat_nu_cols].values, dtype=torch.float32)\n",
    "# y_train_full_tensor = torch.tensor(y_train_full.values, dtype=torch.float32).view(-1, 1)\n",
    "# train_dataset = TensorDataset(X_train_full_tensor, y_train_full_tensor)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # 训练模型\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "# epochs = 50\n",
    "# for epoch in range(epochs):\n",
    "#     best_model.train()\n",
    "#     for inputs, targets in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = best_model(inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# print(\"生成测试集预测结果...\")\n",
    "# best_model.eval()\n",
    "# X_test_tensor = torch.tensor(X_test[cat_nu_cols].values, dtype=torch.float32)\n",
    "# with torch.no_grad():\n",
    "#     test_predictions = best_model(X_test_tensor).numpy()\n",
    "\n",
    "# # 创建预测结果DataFrame\n",
    "# predictions_df = pd.DataFrame({\n",
    "#     'Id': range(len(test_predictions)),\n",
    "#     'Predicted': test_predictions.flatten()\n",
    "# })\n",
    "\n",
    "# # 保存预测结果\n",
    "# predictions_df.to_csv('data/nn_test.csv', index=False)\n",
    "# print(\"预测结果已保存到 data/nn_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
