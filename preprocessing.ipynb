{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集前几行：\n",
      "   listing_id                                              title  \\\n",
      "0     1292132  Land Rover Range Rover Velar 3.0A Si6 R-Dynami...   \n",
      "1     1294696   Mercedes-Benz C-Class C200 Sport Premium Sunroof   \n",
      "2     1311717              Honda Odyssey 2.4A (COE till 09/2027)   \n",
      "3     1310068       Toyota Corolla Altis 1.6A (COE till 12/2028)   \n",
      "4     1325280                     Lexus GS300 (COE till 06/2026)   \n",
      "\n",
      "            make    model                                        description  \\\n",
      "0     land rover    range  1 owner, no repairs needed! it looks great, in...   \n",
      "1  mercedes-benz     c200  rare beautiful white c200 sport premium sunroo...   \n",
      "2          honda  odyssey            comes with warranty. full service done.   \n",
      "3         toyota    altis                                                  0   \n",
      "4          lexus       gs  wear and tear done up. well maintained and reg...   \n",
      "\n",
      "   manufactured original_reg_date     reg_date  type_of_vehicle  \\\n",
      "0        2018.0               NaN  08-mar-2018              suv   \n",
      "1        2017.0               NaN  28-dec-2017     luxury sedan   \n",
      "2        2007.0               NaN  19-sep-2007              mpv   \n",
      "3        2008.0               NaN  15-dec-2008  mid-sized sedan   \n",
      "4        2006.0               NaN  22-dec-2006     luxury sedan   \n",
      "\n",
      "                                   category  ...   mileage      omv       arf  \\\n",
      "0                                  parf car  ...   96000.0  88906.0  132031.0   \n",
      "1                  parf car, premium ad car  ...   85680.0  40678.0   43950.0   \n",
      "2  coe car, premium ad car, low mileage car  ...  138000.0  27994.0   30794.0   \n",
      "3                   coe car, premium ad car  ...  160000.0  16084.0   16084.0   \n",
      "4                   coe car, premium ad car  ...  183000.0  50414.0   55456.0   \n",
      "\n",
      "  opc_scheme  lifespan   eco_category  \\\n",
      "0        NaN       NaN  uncategorized   \n",
      "1        NaN       NaN  uncategorized   \n",
      "2        NaN       NaN  uncategorized   \n",
      "3        NaN       NaN  uncategorized   \n",
      "4        NaN       NaN  uncategorized   \n",
      "\n",
      "                                            features  \\\n",
      "0  3l supercharged v6 p380 engine at 375bhp/450nm...   \n",
      "1  2.0l 4 cylinders inline turbocharged engine, p...   \n",
      "2  2.4l k24a 4 cylinders inline dohc i-vtec, 5 sp...   \n",
      "3  super fuel efficient 1.6l 16 valves dohc vvt-i...   \n",
      "4  powerful 3.0l v6 engine, 227bhp, 6 speed , key...   \n",
      "\n",
      "                                         accessories  indicative_price  \\\n",
      "0  2 x massage/memory/cooling & warmer seat, rear...               NaN   \n",
      "1  multi function steering, electric tailgate, re...               NaN   \n",
      "2  cruise control, touchscreen audio, reverse cam...               NaN   \n",
      "3  leather seats, pioneer dvd audio system with r...               NaN   \n",
      "4  premium upholstery electric seats. memory seat...               NaN   \n",
      "\n",
      "      price  \n",
      "0  193788.0  \n",
      "1   96800.0  \n",
      "2   39800.0  \n",
      "3   44800.0  \n",
      "4   25800.0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "数据集的列名： Index(['listing_id', 'title', 'make', 'model', 'description', 'manufactured',\n",
      "       'original_reg_date', 'reg_date', 'type_of_vehicle', 'category',\n",
      "       'transmission', 'curb_weight', 'power', 'fuel_type', 'engine_cap',\n",
      "       'no_of_owners', 'depreciation', 'coe', 'road_tax', 'dereg_value',\n",
      "       'mileage', 'omv', 'arf', 'opc_scheme', 'lifespan', 'eco_category',\n",
      "       'features', 'accessories', 'indicative_price', 'price'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import MEstimateEncoder, TargetEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import json\n",
    "import math\n",
    "\n",
    "# 加载 train.csv 文件\n",
    "train_file_path = \"./data/train.csv\"\n",
    "test_file_path = \"./data/test.csv\"\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "test = pd.read_csv(test_file_path)\n",
    "\n",
    "train, valid = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 确认数据加载成功，并查看数据的前几行\n",
    "print(\"数据集前几行：\")\n",
    "print(train_df.head())\n",
    "\n",
    "# 输出列名以确认数据集结构\n",
    "print(\"数据集的列名：\", train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode_make(df, column, target):\n",
    "    \"\"\"使用MEstimateEncoder对make进行目标编码\"\"\"\n",
    "    # 初始化编码器\n",
    "    encoder = MEstimateEncoder(\n",
    "        cols=[column],\n",
    "        m=5.0,  # 平滑参数\n",
    "    )\n",
    "    \n",
    "    # 在全量数据上训练编码器\n",
    "    encoder.fit(df[[column]], df[target])\n",
    "    \n",
    "    # 计算默认值（用于处理未见过的类别）\n",
    "    default_mean = df[target].mean()\n",
    "    \n",
    "    return encoder, default_mean\n",
    "\n",
    "def apply_target_encoding(df, column, encoder, default_mean):\n",
    "    \"\"\"应用编码器到数据集\"\"\"\n",
    "    # 创建数据副本并只保留需要的列\n",
    "    df_temp = df[[column]].copy()\n",
    "    \n",
    "    # 转换数据\n",
    "    encoded_values = encoder.transform(df_temp)\n",
    "    \n",
    "    # 将编码结果添加到原始数据框中\n",
    "    df[f\"{column}_target_encoded\"] = encoded_values[column]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categories_train(df, column_name):\n",
    "    \"\"\"在训练数据上初始化并应用MultiLabelBinarizer，返回编码器以备未来使用\"\"\"\n",
    "    # 将字符串转换为列表，每个类别作为列表的一个元素\n",
    "    df[f\"{column_name}_list\"] = df[column_name].apply(lambda x: x.split(', '))\n",
    "\n",
    "    # 初始化MultiLabelBinarizer\n",
    "    mlb = MultiLabelBinarizer()\n",
    "\n",
    "    # 使用MultiLabelBinarizer进行编码\n",
    "    mlb.fit_transform(df[f\"{column_name}_list\"])\n",
    "\n",
    "    return mlb\n",
    "\n",
    "def apply_categories_encoding(df, column_name, mlb):\n",
    "    \"\"\"应用已保存的MultiLabelBinarizer到新DataFrame\"\"\"\n",
    "    # 转换字符串为列表\n",
    "    df[f\"{column_name}_list\"] = df[column_name].apply(lambda x: x.split(', '))\n",
    "\n",
    "    # 使用MultiLabelBinarizer进行编码\n",
    "    df_encoded = mlb.transform(df[f\"{column_name}_list\"])\n",
    "\n",
    "    # 转换回DataFrame并添加列名\n",
    "    df_encoded = pd.DataFrame(df_encoded, columns=mlb.classes_, index=df.index)\n",
    "\n",
    "    # 将编码后的DataFrame合并到原始DataFrame\n",
    "    df = pd.concat([df, df_encoded], axis=1)\n",
    "    df = df.drop(columns=[column_name, f\"{column_name}_list\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode_columns_train(df, columns):\n",
    "    \"\"\"在训练数据上初始化并应用OneHotEncoder，返回编码器以备未来使用\"\"\"\n",
    "    encoders = {}\n",
    "    for column in columns:\n",
    "        onehot_encoder = OneHotEncoder()\n",
    "        # 注意这里转换为DataFrame是为了保持输入格式一致\n",
    "        df_encoded = onehot_encoder.fit_transform(df[[column]])\n",
    "        encoders[column] = onehot_encoder\n",
    "    return encoders\n",
    "\n",
    "def apply_onehot_encoding(df, columns, encoders):\n",
    "    \"\"\"应用已保存的OneHotEncoder到新DataFrame\"\"\"\n",
    "    for column in columns:\n",
    "        # 使用已保存的编码器进行transform操作，并转换为数组\n",
    "        df_encoded = encoders[column].transform(df[[column]]).toarray()\n",
    "\n",
    "        # 转换回DataFrame，列名使用encoder中的类别名称\n",
    "        df_encoded = pd.DataFrame(df_encoded, columns=encoders[column].get_feature_names_out([column]), index=df.index)\n",
    "\n",
    "        # 将编码后的DataFrame合并到原始DataFrame\n",
    "        df = pd.concat([df, df_encoded], axis=1)\n",
    "        df = df.drop(columns=column)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Proecessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列名配置已成功保存到 ./data/columns.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 定义列名\n",
    "columns_dict = {\n",
    "    'del_cols': ['listing_id', 'original_reg_date','opc_scheme', 'lifespan','eco_category', 'indicative_price'],\n",
    "    'text_cols': ['title', 'description', 'features', 'accessories'],\n",
    "    'date_cols': ['reg_date'],\n",
    "    'numeric_cols': ['manufactured', 'curb_weight', 'power', 'engine_cap', 'depreciation', 'coe', 'road_tax', 'dereg_value', 'mileage', 'omv', 'arf', 'year', 'month'],\n",
    "    'log_cols': ['manufactured', 'curb_weight', 'power_log', 'engine_cap_log', 'depreciation_log', 'coe', 'road_tax_log', 'dereg_value_log', 'mileage_log', 'omv_log', 'arf_log', 'year', 'month'],\n",
    "    'root_cols': ['manufactured', 'curb_weight', 'power_root', 'engine_cap_root', 'depreciation_root', 'coe', 'road_tax_root', 'dereg_value_root', 'mileage_root', 'omv_root', 'arf_root', 'year', 'month'],\n",
    "    'categorical_cols': ['make', 'model', 'type_of_vehicle', 'category', 'transmission', 'fuel_type', 'no_of_owners']\n",
    "}\n",
    "\n",
    "# 保存到JSON文件\n",
    "with open('./data/columns.json', 'w') as f:\n",
    "    json.dump(columns_dict, f, indent=4)\n",
    "print(\"列名配置已成功保存到 ./data/columns.json\")\n",
    "\n",
    "# 从字典中读取列名\n",
    "del_cols = columns_dict['del_cols']\n",
    "text_cols = columns_dict['text_cols'] \n",
    "date_cols = columns_dict['date_cols']\n",
    "numeric_cols = columns_dict['numeric_cols']\n",
    "log_cols = columns_dict['log_cols']\n",
    "root_cols = columns_dict['root_cols']\n",
    "categorical_cols = columns_dict['categorical_cols']\n",
    "\n",
    "def get_maxmin_dict(data, numeric_cols):\n",
    "    max_dict = dict()\n",
    "    min_dict = dict()\n",
    "    for feature in numeric_cols:\n",
    "        max_dict[feature] = data[feature].max()\n",
    "        min_dict[feature] = data[feature].min()\n",
    "    return max_dict, min_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_cat(data, del_cols, text_cols, target_encoder, default_mean, mlb_encoder, onehot_encoders):\n",
    "    \"\"\"处理分类特征\"\"\"\n",
    "    data = data.drop(columns=del_cols)\n",
    "    data = data.drop(columns=text_cols)\n",
    "    \n",
    "    # 应用目标编码\n",
    "    data = apply_target_encoding(data, 'make', target_encoder, default_mean)\n",
    "\n",
    "    # 应用多标签二值化编码\n",
    "    data = apply_categories_encoding(data, 'category', mlb_encoder)\n",
    "\n",
    "    # 应用OneHot编码\n",
    "    data = apply_onehot_encoding(data, ['type_of_vehicle', 'fuel_type', 'transmission'], onehot_encoders)\n",
    "\n",
    "    # 处理日期特征\n",
    "    data['reg_date'] = pd.to_datetime(data['reg_date'], format='%d-%b-%Y')  \n",
    "    data['year'] = data['reg_date'].dt.year\n",
    "    data['month'] = data['reg_date'].dt.month\n",
    "    data = data.drop(columns='reg_date')\n",
    "    data['no_of_owners'] = data['no_of_owners'].fillna(2)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_data_num(data, max_dict, min_dict, \n",
    "                       remove_outliers=False,\n",
    "                       do_normalize=False, \n",
    "                       normalize_method='standard'):\n",
    "    \"\"\"\n",
    "    处理数值特征\n",
    "    \n",
    "    参数:\n",
    "    - data: DataFrame, 输入数据\n",
    "    - max_dict: dict, 存储最大值/均值\n",
    "    - min_dict: dict, 存储最小值/标准差\n",
    "    - remove_outliers: bool, 是否移除异常值\n",
    "    - do_normalize: bool, 是否进行归一化\n",
    "    - normalize_method: str, 归一化方法 ('standard' 或 'minmax')\n",
    "    \"\"\"\n",
    "    # 1. 填充缺失值\n",
    "    for feature in numeric_cols:\n",
    "        data[feature] = data[feature].fillna(data[feature].median())\n",
    "    \n",
    "    # 2. 创建异常值掩码\n",
    "    mask = ~((data[numeric_cols] - data[numeric_cols].mean()).abs() > 3 * data[numeric_cols].std()).any(axis=1)\n",
    "    \n",
    "    # 如果需要移除异常值\n",
    "    if remove_outliers:\n",
    "        data = data[mask]\n",
    "    \n",
    "    # 3. 特征转换\n",
    "    # 对长尾特征进行对数变换和平方根变换\n",
    "    long_tail_features = ['omv', 'arf', 'depreciation', 'dereg_value', 'power', 'engine_cap', 'road_tax', 'mileage']\n",
    "    for feature in long_tail_features:\n",
    "        data[f'{feature}_log'] = np.log1p(data[feature])\n",
    "        data[f'{feature}_root'] = np.sqrt(data[feature])\n",
    "\n",
    "    \n",
    "    # 4. 归一化处理\n",
    "    if do_normalize:\n",
    "        # 归一化原始特征\n",
    "        for feature in numeric_cols:\n",
    "            if normalize_method == 'standard':\n",
    "                max_dict[f\"{feature}_mean\"] = data[feature].mean()\n",
    "                min_dict[f\"{feature}_std\"] = data[feature].std()\n",
    "                data[feature] = (data[feature] - max_dict[f\"{feature}_mean\"]) / min_dict[f\"{feature}_std\"]\n",
    "            else:  # minmax\n",
    "                max_dict[feature] = data[feature].max()\n",
    "                min_dict[feature] = data[feature].min()\n",
    "                data[feature] = (data[feature] - min_dict[feature]) / (max_dict[feature] - min_dict[feature])\n",
    "        \n",
    "        # 归一化对数变换和平方根变换后的特征\n",
    "        for feature in long_tail_features:\n",
    "            log_name = f'{feature}_log'\n",
    "            root_name = f'{feature}_root'\n",
    "            \n",
    "            if normalize_method == 'standard':\n",
    "                # 存储均值和标准差\n",
    "                max_dict[f\"{log_name}_mean\"] = data[log_name].mean()\n",
    "                min_dict[f\"{log_name}_std\"] = data[log_name].std()\n",
    "                max_dict[f\"{root_name}_mean\"] = data[root_name].mean()\n",
    "                min_dict[f\"{root_name}_std\"] = data[root_name].std()\n",
    "                \n",
    "                # 标准化\n",
    "                data[log_name] = (data[log_name] - max_dict[f\"{log_name}_mean\"]) / min_dict[f\"{log_name}_std\"]\n",
    "                data[root_name] = (data[root_name] - max_dict[f\"{root_name}_mean\"]) / min_dict[f\"{root_name}_std\"]\n",
    "            else:  # minmax\n",
    "                # 存储最大最小值\n",
    "                max_dict[log_name] = data[log_name].max()\n",
    "                min_dict[log_name] = data[log_name].min()\n",
    "                max_dict[root_name] = data[root_name].max()\n",
    "                min_dict[root_name] = data[root_name].min()\n",
    "                \n",
    "                # 最小最大归一化\n",
    "                data[log_name] = (data[log_name] - min_dict[log_name]) / (max_dict[log_name] - min_dict[log_name])\n",
    "                data[root_name] = (data[root_name] - min_dict[root_name]) / (max_dict[root_name] - min_dict[root_name])\n",
    "    \n",
    "    return data, mask if remove_outliers else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一部分：使用train数据进行预处理...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_log'] = np.log1p(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_root'] = np.sqrt(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_log'] = np.log1p(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_root'] = np.sqrt(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_log'] = np.log1p(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_root'] = np.sqrt(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_log'] = np.log1p(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_root'] = np.sqrt(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_log'] = np.log1p(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_root'] = np.sqrt(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_log'] = np.log1p(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_root'] = np.sqrt(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_log'] = np.log1p(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_root'] = np.sqrt(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_log'] = np.log1p(data[feature])\n",
      "/var/folders/p8/tj4hzkgn3g1cr0tgpcdx97km0000gn/T/ipykernel_3277/3945924141.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{feature}_root'] = np.sqrt(data[feature])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据已保存到 data/processed/ 目录下\n",
      "第二部分：使用全量数据进行预处理...\n",
      "全量训练数据和测试数据已保存到 data/processed/ 目录下\n"
     ]
    }
   ],
   "source": [
    "do_normalize = False\n",
    "normalize_method='minmax'\n",
    "\n",
    "# 第一部分：使用train数据训练模型\n",
    "print(\"第一部分：使用train数据进行预处理...\")\n",
    "X_train, y_train = train.drop(columns=['price']), train['price']\n",
    "X_valid, y_valid = valid.drop(columns=['price']), valid['price']\n",
    "\n",
    "# 使用train数据生成encoders\n",
    "target_encoder_train, default_mean_train = target_encode_make(train, 'make', 'price')\n",
    "mlb_encoder_train = encode_categories_train(train, 'category')\n",
    "onehot_encoders_train = onehot_encode_columns_train(train, ['type_of_vehicle', 'fuel_type', 'transmission'])\n",
    "\n",
    "# 处理分类特征\n",
    "X_train = preprocess_data_cat(X_train, del_cols, text_cols, target_encoder_train, default_mean_train, mlb_encoder_train, onehot_encoders_train)\n",
    "X_valid = preprocess_data_cat(X_valid, del_cols, text_cols, target_encoder_train, default_mean_train, mlb_encoder_train, onehot_encoders_train)\n",
    "\n",
    "# 处理数值特征\n",
    "max_dict_train, min_dict_train = get_maxmin_dict(X_train, numeric_cols)\n",
    "X_train, mask = preprocess_data_num(X_train, max_dict_train, min_dict_train, do_normalize=do_normalize, normalize_method=normalize_method, remove_outliers=False)\n",
    "if mask is not None:\n",
    "    y_train = y_train[mask]\n",
    "X_valid, mask = preprocess_data_num(X_valid, max_dict_train, min_dict_train, do_normalize=do_normalize, normalize_method=normalize_method, remove_outliers=False)\n",
    "\n",
    "# 保存训练用数据\n",
    "import os\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "X_train.to_csv('data/processed/X_train.csv', index=False)\n",
    "y_train.to_csv('data/processed/y_train.csv', index=False)\n",
    "X_valid.to_csv('data/processed/X_valid.csv', index=False)\n",
    "y_valid.to_csv('data/processed/y_valid.csv', index=False)\n",
    "print('训练数据已保存到 data/processed/ 目录下')\n",
    "\n",
    "# 第二部分：使用全量数据进行预处理...\n",
    "print(\"第二部分：使用全量数据进行预处理...\")\n",
    "X_test = test\n",
    "\n",
    "# 1. 先处理全量训练数据\n",
    "X_train_full = train_df.drop(columns=['price'])\n",
    "y_train_full = train_df['price']\n",
    "\n",
    "# 2. 使用全量训练数据生成encoders\n",
    "target_encoder_full, default_mean_full = target_encode_make(train_df, 'make', 'price')\n",
    "mlb_encoder_full = encode_categories_train(train_df, 'category')\n",
    "onehot_encoders_full = onehot_encode_columns_train(train_df, ['type_of_vehicle', 'fuel_type', 'transmission'])\n",
    "\n",
    "# 3. 处理分类特征\n",
    "X_train_full = preprocess_data_cat(X_train_full, del_cols, text_cols, target_encoder_full, default_mean_full, mlb_encoder_full, onehot_encoders_full)\n",
    "X_test = preprocess_data_cat(X_test, del_cols, text_cols, target_encoder_full, default_mean_full, mlb_encoder_full, onehot_encoders_full)\n",
    "\n",
    "# 4. 获取最大最小值字典（使用处理后的全量训练数据）\n",
    "max_dict_full, min_dict_full = get_maxmin_dict(X_train_full, numeric_cols)\n",
    "\n",
    "# 5. 处理数值特征\n",
    "X_train_full, mask = preprocess_data_num(X_train_full, max_dict_full, min_dict_full, do_normalize=do_normalize, normalize_method=normalize_method, remove_outliers=False)\n",
    "if mask is not None:\n",
    "    y_train_full = y_train_full[mask]\n",
    "X_test, mask = preprocess_data_num(X_test, max_dict_full, min_dict_full, do_normalize=do_normalize, normalize_method=normalize_method, remove_outliers=False)\n",
    "\n",
    "# 保存处理后的全量训练数据和测试数据\n",
    "X_train_full.to_csv('data/processed/X_train_full.csv', index=False)\n",
    "y_train_full.to_csv('data/processed/y_train_full.csv', index=False)\n",
    "X_test.to_csv('data/processed/X_test.csv', index=False)\n",
    "print('全量训练数据和测试数据已保存到 data/processed/ 目录下')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
